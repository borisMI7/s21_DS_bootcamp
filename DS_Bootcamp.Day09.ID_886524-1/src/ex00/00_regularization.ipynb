{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 00\n",
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` that you used in the previous day to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/dayofweek.csv')\n",
    "X = df.drop(axis=1, labels=['dayofweek'])\n",
    "y = df['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logreg regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `random_state=21`, `fit_intercept=False`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model\n",
    "\n",
    "\n",
    "The result of the code where you trained and evaluated the baseline model should be exactly like this (use `%%time` to get the info about how long it took to run the cell):\n",
    "\n",
    "```\n",
    "train -  0.62902   |   valid -  0.59259\n",
    "train -  0.64633   |   valid -  0.62963\n",
    "train -  0.63479   |   valid -  0.56296\n",
    "train -  0.65622   |   valid -  0.61481\n",
    "train -  0.63397   |   valid -  0.57778\n",
    "train -  0.64056   |   valid -  0.59259\n",
    "train -  0.64138   |   valid -  0.65926\n",
    "train -  0.65952   |   valid -  0.56296\n",
    "train -  0.64333   |   valid -  0.59701\n",
    "train -  0.63674   |   valid -  0.62687\n",
    "Average accuracy on crossval is 0.60165\n",
    "Std is 0.02943\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.62819 | valid - 0.59259\n",
      "train - 0.64716 | valid - 0.62963\n",
      "train - 0.63479 | valid - 0.57037\n",
      "train - 0.65540 | valid - 0.61481\n",
      "train - 0.63314 | valid - 0.57778\n",
      "train - 0.64056 | valid - 0.59259\n",
      "train - 0.64221 | valid - 0.65926\n",
      "train - 0.65952 | valid - 0.56296\n",
      "train - 0.64333 | valid - 0.59701\n",
      "train - 0.63591 | valid - 0.62687\n",
      "Average accuracy on crossval is 0.60239\n",
      "Std is 0.02852\n",
      "CPU times: user 87.1 ms, sys: 7.33 ms, total: 94.4 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base = LogisticRegression(random_state=21, fit_intercept=False)\n",
    "cv_scores = cross_validate(base, X_train, y_train, return_train_score=True, cv = 10)\n",
    "for train_score, valid_score in zip(cv_scores['train_score'], cv_scores['test_score']):\n",
    "    print(\"train -\", \"{:.5f}\".format(train_score), \"| valid -\", \"{:.5f}\".format(valid_score))\n",
    "\n",
    "print(\"Average accuracy on crossval is {:.5f}\".format(np.mean(cv_scores[\"test_score\"])))\n",
    "print(\"Std is {:.5f}\".format(np.std(cv_scores[\"test_score\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of penalty: `none`, `l1`, `l2` â€“ you can change the values of solver too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_reg  = LogisticRegression(random_state=21, fit_intercept=False, penalty=None, solver='newton-cg')\n",
    "l1_reg = LogisticRegression(random_state=21, fit_intercept=False, penalty='l1', solver='liblinear')\n",
    "l2_reg = LogisticRegression(random_state=21, fit_intercept=False, penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.66694 | valid - 0.63704\n",
      "train - 0.65787 | valid - 0.65926\n",
      "train - 0.66612 | valid - 0.57778\n",
      "train - 0.66529 | valid - 0.62963\n",
      "train - 0.66694 | valid - 0.62222\n",
      "train - 0.65952 | valid - 0.57778\n",
      "train - 0.65045 | valid - 0.69630\n",
      "train - 0.68425 | valid - 0.61481\n",
      "train - 0.66474 | valid - 0.62687\n",
      "train - 0.65651 | valid - 0.60448\n",
      "Average accuracy on crossval is 0.62462\n",
      "Std is 0.03379\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_validate(none_reg, X_train, y_train, return_train_score=True, cv = 10)\n",
    "for train_score, valid_score in zip(cv_scores['train_score'], cv_scores['test_score']):\n",
    "    print(\"train -\", \"{:.5f}\".format(train_score), \"| valid -\", \"{:.5f}\".format(valid_score))\n",
    "\n",
    "print(\"Average accuracy on crossval is {:.5f}\".format(np.mean(cv_scores[\"test_score\"])))\n",
    "print(\"Std is {:.5f}\".format(np.std(cv_scores[\"test_score\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.61830 | valid - 0.54815\n",
      "train - 0.62737 | valid - 0.62222\n",
      "train - 0.60511 | valid - 0.54074\n",
      "train - 0.63644 | valid - 0.62222\n",
      "train - 0.62407 | valid - 0.55556\n",
      "train - 0.62325 | valid - 0.58519\n",
      "train - 0.61253 | valid - 0.63704\n",
      "train - 0.64716 | valid - 0.58519\n",
      "train - 0.63015 | valid - 0.59701\n",
      "train - 0.61367 | valid - 0.59701\n",
      "Average accuracy on crossval is 0.58903\n",
      "Std is 0.03129\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_validate(l1_reg, X_train, y_train, return_train_score=True, cv = 10)\n",
    "for train_score, valid_score in zip(cv_scores['train_score'], cv_scores['test_score']):\n",
    "    print(\"train -\", \"{:.5f}\".format(train_score), \"| valid -\", \"{:.5f}\".format(valid_score))\n",
    "\n",
    "print(\"Average accuracy on crossval is {:.5f}\".format(np.mean(cv_scores[\"test_score\"])))\n",
    "print(\"Std is {:.5f}\".format(np.std(cv_scores[\"test_score\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.62819 | valid - 0.59259\n",
      "train - 0.64716 | valid - 0.62963\n",
      "train - 0.63479 | valid - 0.57037\n",
      "train - 0.65540 | valid - 0.61481\n",
      "train - 0.63314 | valid - 0.57778\n",
      "train - 0.64056 | valid - 0.59259\n",
      "train - 0.64221 | valid - 0.65926\n",
      "train - 0.65952 | valid - 0.56296\n",
      "train - 0.64333 | valid - 0.59701\n",
      "train - 0.63591 | valid - 0.62687\n",
      "Average accuracy on crossval is 0.60239\n",
      "Std is 0.02852\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_validate(l2_reg, X_train, y_train, return_train_score=True, cv = 10)\n",
    "for train_score, valid_score in zip(cv_scores['train_score'], cv_scores['test_score']):\n",
    "    print(\"train -\", \"{:.5f}\".format(train_score), \"| valid -\", \"{:.5f}\".format(valid_score))\n",
    "\n",
    "print(\"Average accuracy on crossval is {:.5f}\".format(np.mean(cv_scores[\"test_score\"])))\n",
    "print(\"Std is {:.5f}\".format(np.std(cv_scores[\"test_score\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `probability=True`, `kernel='linear'`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_svm = SVC(probability=True,kernel='linear', random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.70486 | valid - 0.65926\n",
      "train - 0.69662 | valid - 0.75556\n",
      "train - 0.69415 | valid - 0.62222\n",
      "train - 0.70239 | valid - 0.65185\n",
      "train - 0.69085 | valid - 0.65185\n",
      "train - 0.68920 | valid - 0.64444\n",
      "train - 0.69250 | valid - 0.72593\n",
      "train - 0.70074 | valid - 0.62222\n",
      "train - 0.69605 | valid - 0.61940\n",
      "train - 0.71087 | valid - 0.63433\n",
      "Average accuracy on crossval is 0.65871\n",
      "Std is 0.04359\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_validate(base_svm, X_train, y_train, return_train_score=True, cv = 10)\n",
    "for train_score, valid_score in zip(cv_scores['train_score'], cv_scores['test_score']):\n",
    "    print(\"train -\", \"{:.5f}\".format(train_score), \"| valid -\", \"{:.5f}\".format(valid_score))\n",
    "\n",
    "print(\"Average accuracy on crossval is {:.5f}\".format(np.mean(cv_scores[\"test_score\"])))\n",
    "print(\"Std is {:.5f}\".format(np.std(cv_scores[\"test_score\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6587064676616916\n",
      "2 0.6683637368711995\n",
      "3 0.6794914317302376\n",
      "4 0.6935986733001658\n",
      "5 0.6995245992260919\n",
      "6 0.6987949143173022\n",
      "7 0.7069375345494748\n",
      "8 0.7195577667219458\n",
      "9 0.7247484798231068\n",
      "10 0.7277114427860697\n",
      "11 0.7321614151464898\n",
      "12 0.7336373687119956\n",
      "13 0.7336373687119956\n",
      "14 0.7336373687119956\n",
      "15 0.7351188501934771\n",
      "16 0.7410613598673301\n",
      "17 0.7388336097291323\n",
      "18 0.7388280818131564\n",
      "19 0.7388280818131564\n"
     ]
    }
   ],
   "source": [
    "for c in range(1, 20, 1):\n",
    "    m = SVC(probability=True, kernel='linear', random_state=21, C=c)\n",
    "    print(c, np.mean(cross_validate(m, X_train, y_train, cv=10)['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameter `max_depth=10` and `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.81039 | valid - 0.74074\n",
      "train - 0.77741 | valid - 0.74074\n",
      "train - 0.83347 | valid - 0.70370\n",
      "train - 0.79720 | valid - 0.76296\n",
      "train - 0.82440 | valid - 0.75556\n",
      "train - 0.80379 | valid - 0.68889\n",
      "train - 0.80709 | valid - 0.76296\n",
      "train - 0.80132 | valid - 0.65926\n",
      "train - 0.80807 | valid - 0.75373\n",
      "train - 0.80478 | valid - 0.68657\n",
      "Average accuracy on crossval is 0.72551\n",
      "Std is 0.03562\n"
     ]
    }
   ],
   "source": [
    "base_tree = DecisionTreeClassifier(max_depth=10, random_state=21)\n",
    "cv_scores = cross_validate(base_tree, X_train, y_train, return_train_score=True, cv = 10)\n",
    "for train_score, valid_score in zip(cv_scores['train_score'], cv_scores['test_score']):\n",
    "    print(\"train -\", \"{:.5f}\".format(train_score), \"| valid -\", \"{:.5f}\".format(valid_score))\n",
    "\n",
    "print(\"Average accuracy on crossval is {:.5f}\".format(np.mean(cv_scores[\"test_score\"])))\n",
    "print(\"Std is {:.5f}\".format(np.std(cv_scores[\"test_score\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `max_depth`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.3553178551686015\n",
      "2 0.42948590381426205\n",
      "3 0.4613985627418463\n",
      "4 0.5088944168048645\n",
      "5 0.5430127142067441\n",
      "6 0.5956992813709232\n",
      "7 0.6498894416804866\n",
      "8 0.6609839690436705\n",
      "9 0.7032504145936983\n",
      "10 0.7255113322277501\n",
      "11 0.7699889441680486\n",
      "12 0.8041348811498065\n",
      "13 0.8300884466556109\n",
      "14 0.8523548922056385\n",
      "15 0.8545881702598119\n",
      "16 0.8657103372028745\n",
      "17 0.8738750690989496\n",
      "18 0.8805527915975677\n",
      "19 0.8805417357656165\n"
     ]
    }
   ],
   "source": [
    "for d in range(1, 20):\n",
    "    m = DecisionTreeClassifier(random_state=21, max_depth=d)\n",
    "    print(d, float(np.mean(cross_validate(m, X_train, y_train, cv=10)['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `n_estimators=50`, `max_depth=14`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.96455 | valid - 0.88148\n",
      "train - 0.96208 | valid - 0.91852\n",
      "train - 0.96785 | valid - 0.86667\n",
      "train - 0.96455 | valid - 0.89630\n",
      "train - 0.96538 | valid - 0.91111\n",
      "train - 0.96538 | valid - 0.88148\n",
      "train - 0.97115 | valid - 0.91852\n",
      "train - 0.96867 | valid - 0.85185\n",
      "train - 0.97364 | valid - 0.88060\n",
      "train - 0.97941 | valid - 0.86567\n",
      "Average accuracy on crossval is 0.88722\n",
      "Std is 0.02204\n"
     ]
    }
   ],
   "source": [
    "base_forest = RandomForestClassifier(n_estimators=50, max_depth=14, random_state=21)\n",
    "cv_scores = cross_validate(base_forest, X_train, y_train, return_train_score=True, cv = 10)\n",
    "for train_score, valid_score in zip(cv_scores['train_score'], cv_scores['test_score']):\n",
    "    print(\"train -\", \"{:.5f}\".format(train_score), \"| valid -\", \"{:.5f}\".format(valid_score))\n",
    "\n",
    "print(\"Average accuracy on crossval is {:.5f}\".format(np.mean(cv_scores[\"test_score\"])))\n",
    "print(\"Std is {:.5f}\".format(np.std(cv_scores[\"test_score\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the new cells try different values of the parameters `max_depth` and `n_estimators`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.40279712548369256\n",
      "2 0.46214483139856277\n",
      "3 0.4859038142620232\n",
      "4 0.5170757324488668\n",
      "5 0.576384742951907\n",
      "6 0.6335102266445551\n",
      "7 0.6787672747374239\n",
      "8 0.7210503040353787\n",
      "9 0.7641238253178552\n",
      "10 0.7952294085129906\n",
      "11 0.8323548922056384\n",
      "12 0.8597844112769486\n",
      "13 0.8679380873410725\n",
      "14 0.8872194582642343\n",
      "15 0.8901824212271974\n",
      "16 0.8916749585406301\n",
      "17 0.900580431177446\n",
      "18 0.9072692095080155\n",
      "19 0.9087506909894969\n",
      "20 0.9087396351575455\n",
      "21 0.9079933665008291\n",
      "22 0.910978441127695\n",
      "23 0.9117025981205085\n",
      "24 0.9080099502487562\n"
     ]
    }
   ],
   "source": [
    "for d in range(1, 25):\n",
    "    m = RandomForestClassifier(n_estimators=50, max_depth=d, random_state=21)\n",
    "    print(d, float(np.mean(cross_validate(m, X_train, y_train, cv=10)['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.9117025981205085\n",
      "100 0.91171365395246\n",
      "150 0.9131951354339414\n",
      "200 0.9124543946932008\n",
      "250 0.9117025981205085\n",
      "300 0.9117081260364841\n",
      "350 0.9139358761746822\n",
      "400 0.9139358761746822\n",
      "450 0.9139414040906578\n",
      "500 0.9139414040906578\n",
      "550 0.9131951354339414\n",
      "600 0.9124543946932006\n",
      "650 0.9131951354339414\n"
     ]
    }
   ],
   "source": [
    "for n in range(50, 700, 50):\n",
    "    m = RandomForestClassifier(n_estimators=n, max_depth=23, random_state=21)\n",
    "    print(n, float(np.mean(cross_validate(m, X_train, y_train, cv=10)['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and use it to make predictions for the test dataset.\n",
    "2. Calculate the final accuracy.\n",
    "3. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your test dataset).\n",
    "4. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319526627218935"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(n_estimators=350, max_depth=23, random_state=21)\n",
    "best_model.fit(X_train, y_train)\n",
    "test_pred = best_model.predict(X_test)\n",
    "accuracy_score(y_pred=test_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25.925925925925924\n",
      "1 7.2727272727272725\n",
      "2 6.666666666666667\n",
      "3 2.5\n",
      "4 14.285714285714285\n",
      "5 7.4074074074074066\n",
      "6 1.4084507042253522\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_pred=test_pred, y_true=y_test)\n",
    "for i, cls in enumerate(cm):\n",
    "    sum = cls.sum()\n",
    "    err = sum - cls[i]\n",
    "    frac = err/sum*100\n",
    "    print(i, frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
