{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import joblib\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor \n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654cc866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/epi_r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6eb2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_food = [\n",
    "    'almond', 'amaretto', 'anchovy', 'anise', 'apple', 'apricot', 'artichoke', 'arugula', 'asparagus', 'avocado',\n",
    "    'bacon', 'banana', 'barley', 'basil', 'beef', 'beet', 'bell pepper', 'berry', 'blackberry', 'blue cheese',\n",
    "    'blueberry', 'bok choy', 'bran', 'bread', 'brie', 'broccoli', 'bulgur', 'burrito', 'butter', 'buttermilk',\n",
    "    'butternut squash', 'cabbage', 'candy', 'cantaloupe', 'capers', 'carrot', 'cashew', 'cauliflower', 'caviar',\n",
    "    'celery', 'cheddar', 'cheese', 'cherry', 'chestnut', 'chicken', 'chickpea', 'chile pepper', 'chili', 'chive',\n",
    "    'chocolate', 'coconut', 'cod', 'coriander', 'corn', 'crab', 'cranberry', 'cream cheese', 'cucumber', 'curry',\n",
    "    'custard', 'dairy', 'date', 'duck', 'egg', 'eggplant', 'endive', 'fennel', 'feta', 'fig', 'fish', 'garlic',\n",
    "    'goat cheese', 'gouda', 'grape', 'grapefruit', 'green bean', 'green onion/scallion', 'ham', 'hamburger',\n",
    "    'hazelnut', 'honey', 'hummus', 'ice cream', 'jalapeño', 'kale', 'kiwi', 'lamb', 'lemon', 'lentil', 'lettuce',\n",
    "    'lima bean', 'lime', 'lobster', 'macaroni and cheese', 'mango', 'maple syrup', 'mayonnaise', 'meatball',\n",
    "    'melon', 'mint', 'mushroom', 'mussel', 'mustard', 'nutmeg', 'oatmeal', 'olive', 'omelet', 'onion', 'orange',\n",
    "    'oregano', 'oyster', 'pancake', 'papaya', 'paprika', 'parmesan', 'parsley', 'parsnip', 'pasta', 'peanut',\n",
    "    'pear', 'pecan', 'pepper', 'persimmon', 'pineapple', 'pistachio', 'pizza', 'plum', 'pomegranate', 'pork',\n",
    "    'potato', 'poultry', 'prosciutto', 'prune', 'pumpkin', 'quail', 'quinoa', 'radish', 'raisin', 'raspberry',\n",
    "    'rice', 'ricotta', 'rosemary', 'salmon', 'salsa', 'sausage', 'scallop', 'seafood', 'sesame', 'shallot',\n",
    "    'shrimp', 'spinach', 'squash', 'steak', 'strawberry', 'sugar snap pea', 'sweet potato/yam', 'swiss cheese',\n",
    "    'tangerine', 'tapioca', 'tarragon', 'tea', 'thyme', 'tilapia', 'tofu', 'tomato', 'trout', 'tuna', 'turnip',\n",
    "    'vanilla', 'veal', 'vegetable', 'walnut', 'wasabi', 'watermelon', 'wild rice', 'yellow squash', 'yogurt',\n",
    "    'zucchini'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[list_of_food]\n",
    "y = df[['rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80617896",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b62304",
   "metadata": {},
   "source": [
    "<h1> Regression </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tqdmGridSearchCV(GridSearchCV):\n",
    "    def _run_search(self, evaluate_candidates):\n",
    "        par = ParameterGrid(self.param_grid)\n",
    "        for i in tqdm(par):\n",
    "            evaluate_candidates([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(grids, grid_dict, X_train, X_test, y_train, y_test):\n",
    "        scores = {}\n",
    "        for_dataframe = {'model': [], 'params': [], 'valid_score': []}\n",
    "        for grid in grids:\n",
    "            reg = grid\n",
    "            reg.fit(X_train, y_train)\n",
    "\n",
    "            best_model = reg.best_estimator_\n",
    "            y_pred = best_model.predict(X_test)\n",
    "\n",
    "            print(f'Estimator: {grid_dict[grid]}')\n",
    "            for_dataframe['model'].append(grid_dict[grid])\n",
    "\n",
    "            print(f'Best params: {reg.best_params_}')\n",
    "            for_dataframe['params'].append(reg.best_params_)\n",
    "\n",
    "            print(f'Best training accuracy: {np.abs(reg.best_score_)}')\n",
    "\n",
    "            print(f'Validation set accuracy score for best params: {np.abs(mean_squared_error(y_test, y_pred))}')\n",
    "            for_dataframe['valid_score'].append(np.abs(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "            scores[grid_dict[grid]] = np.abs(mean_squared_error(y_test, y_pred))\n",
    "            print()\n",
    "            \n",
    "        name_best_model = sorted(scores.items(), key = lambda x: x[1], reverse = False)\n",
    "        print(f'Classifier with the best RMSE: {name_best_model[0][0]}')\n",
    "        return name_best_model[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a94d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_param = {'fit_intercept': [True, False], 'positive': [True, False]}\n",
    "tree_reg_param = {'max_depth': np.arange(1, 10, 1), 'min_samples_split': np.arange(2, 5, 1), 'min_samples_leaf': np.arange(1, 5, 1)}\n",
    "randf_reg_param = {'n_estimators': [5, 10, 50, 100], 'max_depth': np.arange(1, 10, 1),'min_samples_split': np.arange(2, 5, 1), 'min_samples_leaf': np.arange(1, 5, 1)}\n",
    "\n",
    "lr = tqdmGridSearchCV(estimator = LinearRegression(), param_grid = lin_reg_param, scoring = 'neg_root_mean_squared_error', n_jobs = -1)\n",
    "tr = tqdmGridSearchCV(estimator = DecisionTreeRegressor(random_state = 21), param_grid = tree_reg_param, scoring = 'neg_root_mean_squared_error', n_jobs = -1)\n",
    "rfr = tqdmGridSearchCV(estimator = RandomForestRegressor(random_state = 21), param_grid = randf_reg_param, scoring = 'neg_root_mean_squared_error', n_jobs = -1)\n",
    "\n",
    "grids = [lr, tr, rfr]\n",
    "grid_dict = {lr: 'LinearRegression', tr: 'DecisionTreeRegressor', rfr: 'RandomForestRegressor'}\n",
    "\n",
    "choose(grids, grid_dict, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c9a750",
   "metadata": {},
   "source": [
    "<h1> Ensembles </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22465f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'MSE is {mse:.5f}')\n",
    "    print(f'RMSE is {np.sqrt(mse):.5f}')\n",
    "    print(f'R2 is {r2:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd54d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_b = lr.best_estimator_\n",
    "tr_b = tr.best_estimator_\n",
    "rfr_b = rfr.best_estimator_\n",
    "\n",
    "voting_estimators = [('LinearRegression', lr_b), ('DecisionTreeRegressor', tr_b), ('RandomForestRegressor', rfr_b)]\n",
    "voting_params = {'weights': list(itertools.combinations([1, 2, 3, 4, 5], 3))}\n",
    "\n",
    "model_voting = tqdmGridSearchCV(estimator = VotingRegressor(estimators = voting_estimators), param_grid = voting_params, cv = 5, n_jobs = -1, scoring = 'neg_root_mean_squared_error')\n",
    "print_metrics(model_voting, X_train, y_train, X_test, y_test)\n",
    "print(f'{model_voting.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
    "tr_b = DecisionTreeRegressor(**p, random_state = 21)\n",
    "\n",
    "bagging_params = {'n_estimators': [5, 10, 50, 100]}\n",
    "\n",
    "model_bagging = tqdmGridSearchCV(estimator = BaggingRegressor(estimator = tr_b, n_jobs = -1, random_state = 21), param_grid = bagging_params, cv = 5, n_jobs = -1, scoring = 'neg_root_mean_squared_error')\n",
    "print_metrics(model_bagging, X_train, y_train, X_test, y_test)\n",
    "print(f'{model_bagging.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_b = LinearRegression(n_jobs = -1)\n",
    "p = {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
    "tr_b = DecisionTreeRegressor(**p, random_state = 21)\n",
    "p = {'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
    "rfr_b = RandomForestRegressor(**p, random_state = 21)\n",
    "\n",
    "stacking_estimators = [('LinearRegression', lr_b), ('DecisionTreeRegressor', tr_b), ('RandomForestRegressor', rfr_b)]\n",
    "\n",
    "model_stacking = StackingRegressor(estimators = stacking_estimators, final_estimator = RidgeCV(cv = 5, scoring = 'neg_root_mean_squared_error'), cv = 5, n_jobs = -1)\n",
    "print_metrics(model_stacking, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71667f1",
   "metadata": {},
   "source": [
    "<h1> Naive regression </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50470b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive = y_test.copy()\n",
    "y_naive['predict'] = y_naive['rating'].mean()\n",
    "np.sqrt(((y_naive.rating - y_naive.predict) ** 2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8289a63",
   "metadata": {},
   "source": [
    "<h1> Classifier </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a2887",
   "metadata": {},
   "source": [
    "Binarize the target column by rounding the ratings to the closest integer. This will be your classes.\n",
    "Try different algorithms and their hyperparameters for class prediction. Choose the best on cross-validation and find the score (accuracy) on the test subsample.\n",
    "Compare the metrics using accuracy. Calculate the accuracy of a naive classificator that predicts the most common class.\n",
    "Binarize the target column again by converting the integers to classes ‘bad’ (0, 1), ‘so-so’ (2, 3), ‘great’ (4, 5).\n",
    "Try different algorithms and their hyperparameters for class prediction. Choose the best on cross-validation and find the score on the test subsample.\n",
    "Compare the metrics using accuracy. Calculate the accuracy of a naive classificator that predicts the most common class.\n",
    "What is worse: to predict a bad rating which is good in real life, or to predict a good rating which is bad in real life? Replace accuracy with the appropriate metric.\n",
    "Try different algorithms and their hyperparameters for class prediction with the new metric. Choose the best and find the score on the test subsample.\n",
    "Try different ensembles and their hyperparameters. Choose the best and find the score on the test subsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68042ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[['rating']].round(0)\n",
    "y['rating'] = y['rating'].astype(int)\n",
    "y['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac52158",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(grids, grid_dict, X_train, X_test, y_train, y_test):\n",
    "        scores = {}\n",
    "        for_dataframe = {'model': [], 'params': [], 'valid_score': []}\n",
    "        for grid in grids:\n",
    "            reg = grid\n",
    "            reg.fit(X_train, y_train)\n",
    "\n",
    "            best_model = reg.best_estimator_\n",
    "            y_pred = best_model.predict(X_test)\n",
    "\n",
    "            print(f'Estimator: {grid_dict[grid]}')\n",
    "            for_dataframe['model'].append(grid_dict[grid])\n",
    "\n",
    "            print(f'Best params: {reg.best_params_}')\n",
    "            for_dataframe['params'].append(reg.best_params_)\n",
    "\n",
    "            print(f'Best training accuracy: {np.abs(reg.best_score_)}')\n",
    "\n",
    "            print(f'Validation set accuracy score for best params: {np.abs(accuracy_score(y_test, y_pred))}')\n",
    "            for_dataframe['valid_score'].append(np.abs(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "            scores[grid_dict[grid]] = np.abs(accuracy_score(y_test, y_pred))\n",
    "            print()\n",
    "            \n",
    "        name_best_model = sorted(scores.items(), key = lambda x: x[1], reverse = False)\n",
    "        print(f'Classifier with the best accuracy: {name_best_model[0][0]}')\n",
    "        return name_best_model[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52276179",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {'kernel':('linear', 'rbf', 'sigmoid'), 'C':[0.01, 0.1, 1, 1.5, 5, 10], 'gamma': ['scale', 'auto'], 'class_weight':('balanced', None)}\n",
    "tree_params = {'max_depth': [i for i in range(1, 50)], 'class_weight': ('balanced', None), 'criterion': ('entropy', 'gini')}\n",
    "rf_params = {'max_depth': [i for i in range(1, 50)], 'class_weight': ('balanced', None), 'criterion': ('entropy', 'gini'), 'n_estimators': [5, 10, 50, 100]}\n",
    "\n",
    "gs_svm = tqdmGridSearchCV(estimator = SVC(random_state = 21, probability = True), param_grid = svm_params, scoring = 'accuracy', n_jobs = -1)\n",
    "gs_tree = tqdmGridSearchCV(estimator = DecisionTreeClassifier(random_state = 21), param_grid = tree_params, scoring = 'accuracy', n_jobs = -1)\n",
    "gs_rf = tqdmGridSearchCV(estimator = RandomForestClassifier(random_state = 21), param_grid = rf_params, scoring = 'accuracy', n_jobs = -1)\n",
    "\n",
    "grids = [gs_svm, gs_tree, gs_rf]\n",
    "\n",
    "grid_dict = {gs_svm: 'SVM', gs_tree: 'DecisionTreeClassifier', gs_rf: 'RandomForestClassifier'}\n",
    "\n",
    "choose(grids, grid_dict, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8959c41d",
   "metadata": {},
   "source": [
    "Estimator: SVM\n",
    "Best params: {'C': 1, 'kernel': 'rbf'}\n",
    "Best training accuracy: 0.6757545567321572\n",
    "Validation set accuracy score for best params: 0.6750709108099591\n",
    "\n",
    "Estimator: DecisionTreeClassifier\n",
    "Best params: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 1}\n",
    "Best training accuracy: 0.6737057924742806\n",
    "Validation set accuracy score for best params: 0.6738102741884652\n",
    "\n",
    "Estimator: RandomForestClassifier\n",
    "Best params: {'class_weight': None, 'criterion': 'gini', 'max_depth': 38, 'n_estimators': 100}\n",
    "Best training accuracy: 0.6802458790232498\n",
    "Validation set accuracy score for best params: 0.6760163882760795"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f7e988",
   "metadata": {},
   "source": [
    "<h3> naive </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive = y_test.copy()\n",
    "y_naive['predict'] = y_test['rating'].mode()[0]\n",
    "accuracy_score(y_naive['rating'], y_naive['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046bd3ff",
   "metadata": {},
   "source": [
    "<h3> binarize from int to classes </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b021de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.copy()\n",
    "y['rating'] = y['rating'].case_when([\n",
    "    (y['rating'] <= 1, 'bad'),\n",
    "    ((y['rating'] <= 3) & (y['rating'] >= 2), 'so-so'),\n",
    "    ((y['rating'] <= 5) & (y['rating'] >= 4), 'great')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f760cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive = y_test.copy()\n",
    "y_naive['predict'] = y_test['rating'].mode()[0]\n",
    "accuracy_score(y_naive['rating'], y_naive['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c845ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_naive = y_test.copy()\n",
    "y_naive['predict'] = y_test['rating'].mode()[0]\n",
    "f1_score(y_naive['rating'], y_naive['predict'], average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f6c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(grids, grid_dict, X_train, X_test, y_train, y_test):\n",
    "        scores = {}\n",
    "        for_dataframe = {'model': [], 'params': [], 'valid_score': []}\n",
    "        for grid in grids:\n",
    "            reg = grid\n",
    "            reg.fit(X_train, y_train)\n",
    "\n",
    "            best_model = reg.best_estimator_\n",
    "            y_pred = best_model.predict(X_test)\n",
    "\n",
    "            print(f'Estimator: {grid_dict[grid]}')\n",
    "            for_dataframe['model'].append(grid_dict[grid])\n",
    "\n",
    "            print(f'Best params: {reg.best_params_}')\n",
    "            for_dataframe['params'].append(reg.best_params_)\n",
    "\n",
    "            print(f'Best training f1_score: {np.abs(reg.best_score_)}')\n",
    "\n",
    "            print(f'Validation set f1_score for best params: {np.abs(f1_score(y_test, y_pred, average = \"weighted\"))}')\n",
    "            for_dataframe['valid_score'].append(np.abs(f1_score(y_test, y_pred, average = \"weighted\")))\n",
    "\n",
    "            scores[grid_dict[grid]] = np.abs(f1_score(y_test, y_pred, average = \"weighted\"))\n",
    "            print()\n",
    "            \n",
    "        name_best_model = sorted(scores.items(), key = lambda x: x[1], reverse = True)\n",
    "        print(f'Classifier with the best f1_score: {name_best_model[0][0]}')\n",
    "        return name_best_model[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db714f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_params = {'kernel':('linear', 'rbf', 'sigmoid'), 'C':[0.01, 1, 5, 10]}\n",
    "tree_params = {'max_depth': [i for i in range(1, 50)], 'class_weight': ('balanced', None), 'criterion': ('entropy', 'gini')}\n",
    "rf_params = {'max_depth': [i for i in range(1, 50)], 'class_weight': ('balanced', None), 'criterion': ('entropy', 'gini'), 'n_estimators': [5, 10, 50, 100]}\n",
    "\n",
    "#gs_svm = tqdmGridSearchCV(estimator = SVC(random_state = 21, probability = True), param_grid = svm_params, scoring = 'f1_weighted', n_jobs = -1)\n",
    "gs_tree = tqdmGridSearchCV(estimator = DecisionTreeClassifier(random_state = 21), param_grid = tree_params, scoring = 'f1_weighted', n_jobs = -1)\n",
    "gs_rf = tqdmGridSearchCV(estimator = RandomForestClassifier(random_state = 21), param_grid = rf_params, scoring = 'f1_weighted', n_jobs = -1)\n",
    "\n",
    "grids = [gs_tree, gs_rf]\n",
    "\n",
    "grid_dict = {gs_tree: 'DecisionTreeClassifier', gs_rf: 'RandomForestClassifier'}\n",
    "\n",
    "choose(grids, grid_dict, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c95fc",
   "metadata": {},
   "source": [
    "best with f1\n",
    "\n",
    "Estimator: SVM\n",
    "Best params: {'C': 5, 'kernel': 'rbf'}\n",
    "Best training f1_score: 0.7337721319736552\n",
    "\n",
    "Estimator: DecisionTreeClassifier\n",
    "Best params: {'class_weight': None, 'criterion': 'gini', 'max_depth': 20}\n",
    "Best training f1_score: 0.726571335535054\n",
    "\n",
    "Estimator: RandomForestClassifier\n",
    "Best params: {'class_weight': None, 'criterion': 'gini', 'max_depth': 45, 'n_estimators': 100}\n",
    "Best training f1_score: 0.7340618439935772"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92ec9b",
   "metadata": {},
   "source": [
    "<h3> ensembles </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    print(f'f1_score is {f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5caa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_b = SVC(C = 5, kernel = 'rbf', random_state = 21)\n",
    "tree_b = DecisionTreeClassifier(class_weight = None, criterion = 'gini', max_depth = 20, random_state = 21)\n",
    "rfc_b = RandomForestClassifier(class_weight = None, criterion = 'gini', max_depth = 45, n_estimators = 100, random_state = 21)\n",
    "\n",
    "voting_estimators = [('SVC', svm_b), ('DecisionTreeClassifier', tree_b), ('RandomForestClassifier', rfc_b)]\n",
    "voting_params = {'weights': list(itertools.combinations([1, 2, 3, 4, 5], 3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abac423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_voting = tqdmGridSearchCV(estimator = VotingClassifier(estimators = voting_estimators), param_grid = voting_params, cv = 5, n_jobs = -1, scoring = 'f1_weighted')\n",
    "print_metrics(model_voting, X_train, y_train, X_test, y_test)\n",
    "print(f'{model_voting.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f4b5d",
   "metadata": {},
   "source": [
    "voting\n",
    "f1_score is 0.73574\n",
    "{'weights': (1, 2, 3)}\n",
    "\n",
    "bagging\n",
    "f1_score is 0.73907\n",
    "{'n_estimators': 100}\n",
    "\n",
    "stacking\n",
    "f1_score is 0.72771\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_parametrs = {'n_estimators': [5, 10, 50, 100]}\n",
    "model = BaggingClassifier(estimator = svm_b, random_state = 21)\n",
    "model_bagging = tqdmGridSearchCV(model, bag_parametrs, n_jobs = -1, scoring = 'f1_weighted')\n",
    "\n",
    "print_metrics(model_bagging, X_train, y_train, X_test, y_test)\n",
    "print(f'{model_bagging.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_estimators = [('SVC', svm_b), ('DecisionTreeClassifier', tree_b), ('RandomForestClassifier', rfc_b)]\n",
    "\n",
    "model_stacking = StackingClassifier(estimators = stacking_estimators, final_estimator = LogisticRegression(solver = 'liblinear'), cv = 5, n_jobs = -1)\n",
    "print_metrics(model_stacking, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055aba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_bagging.best_estimator_, 'best_recipes_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = joblib.load('best_recipes_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3414719",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ca448",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y1, average = 'weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
